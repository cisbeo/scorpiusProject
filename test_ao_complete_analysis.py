#!/usr/bin/env python3
"""
Analyse compl√®te multi-documents d'un appel d'offres public
Con√ßu pour un Bid Manager avec 3 ans d'exp√©rience
"""

import asyncio
import logging
from pathlib import Path
import time
from datetime import datetime
import json
import uuid
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass, asdict
import re

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Disable verbose loggers
for name in ["httpx", "httpcore", "sqlalchemy"]:
    logging.getLogger(name).setLevel(logging.WARNING)


@dataclass
class DocumentAnalysis:
    """R√©sultat d'analyse d'un document"""
    filename: str
    doc_type: str  # CCTP, CCAP, RC
    text_length: int
    pages: int
    extraction_time_ms: int
    chunks_count: int
    key_elements: Dict[str, Any]
    requirements: List[str]
    risks: List[Dict[str, str]]
    score: float


@dataclass
class CrossDocumentAnalysis:
    """Analyse crois√©e des documents"""
    total_requirements: int
    contradictions: List[Dict[str, str]]
    missing_elements: List[str]
    timeline_consistency: bool
    financial_clarity: float
    technical_complexity: float
    global_score: float


@dataclass
class BidManagerReport:
    """Rapport complet pour le Bid Manager"""
    ao_reference: str
    analysis_date: str
    documents_analyzed: List[DocumentAnalysis]
    cross_analysis: CrossDocumentAnalysis
    rag_insights: Dict[str, List[Dict[str, str]]]
    go_no_go_score: float
    go_no_go_decision: str
    key_risks: List[Dict[str, str]]
    action_plan: List[Dict[str, str]]
    questions_for_buyer: List[str]
    competitive_positioning: Dict[str, Any]
    executive_summary: str


class AOCompleteAnalyzer:
    """Analyseur complet d'appels d'offres"""

    def __init__(self):
        self.documents = {}
        self.chunks_db = {}
        self.embeddings_cache = {}
        self.analysis_results = {}

    async def analyze_complete_ao(self, ao_directory: Path) -> BidManagerReport:
        """Analyse compl√®te d'un dossier d'appel d'offres"""

        logger.info("="*70)
        logger.info("üöÄ ANALYSE COMPL√àTE D'APPEL D'OFFRES - SYST√àME RAG AVANC√â")
        logger.info("="*70)
        logger.info(f"üìÅ Dossier: {ao_directory}")
        logger.info(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        logger.info("="*70)

        # Phase 1: Ingestion multi-documents
        documents_analysis = await self._phase1_multi_doc_ingestion(ao_directory)

        # Phase 2: Analyse crois√©e
        cross_analysis = await self._phase2_cross_document_analysis(documents_analysis)

        # Phase 3: Chunking optimis√©
        await self._phase3_optimized_chunking(documents_analysis)

        # Phase 4: RAG Queries avanc√©es
        rag_insights = await self._phase4_advanced_rag_queries()

        # Phase 5: Analyse de conformit√©
        conformity_analysis = await self._phase5_conformity_analysis()

        # Phase 6: G√©n√©ration du rapport
        report = await self._phase6_generate_bid_manager_report(
            documents_analysis, cross_analysis, rag_insights, conformity_analysis
        )

        return report

    async def _phase1_multi_doc_ingestion(self, ao_directory: Path) -> List[DocumentAnalysis]:
        """Phase 1: Ingestion parall√®le des documents PDF"""

        logger.info("\n" + "="*60)
        logger.info("üìö PHASE 1: INGESTION MULTI-DOCUMENTS")
        logger.info("="*60)

        from src.processors.pdf_processor import PDFProcessor
        pdf_processor = PDFProcessor()

        # Trouver tous les PDFs
        pdf_files = list(ao_directory.glob("*.pdf"))
        logger.info(f"üìÑ {len(pdf_files)} documents PDF trouv√©s")

        # Traiter chaque document
        documents_analysis = []

        for pdf_path in pdf_files:
            logger.info(f"\n{'='*40}")
            logger.info(f"üìñ Traitement: {pdf_path.name}")
            logger.info(f"{'='*40}")

            # D√©terminer le type de document
            doc_type = self._determine_doc_type(pdf_path.name)
            logger.info(f"üìë Type identifi√©: {doc_type}")

            # Lire et traiter le PDF
            with open(pdf_path, 'rb') as f:
                file_content = f.read()

            logger.info(f"üìä Taille: {len(file_content) / (1024*1024):.2f} MB")

            start_time = time.time()
            result = await pdf_processor.process_document(
                file_content=file_content,
                filename=pdf_path.name
            )
            processing_time = int((time.time() - start_time) * 1000)

            if not result.success:
                logger.error(f"‚ùå √âchec du traitement: {result.metadata.get('error')}")
                continue

            # Extraire les √©l√©ments cl√©s selon le type de document
            key_elements = await self._extract_key_elements(result.raw_text, doc_type)

            # Analyser les exigences
            requirements = self._extract_requirements(result.raw_text, doc_type)

            # Identifier les risques
            risks = self._identify_risks(result.raw_text, doc_type)

            # Calculer le score du document
            doc_score = self._calculate_document_score(key_elements, requirements, risks)

            doc_analysis = DocumentAnalysis(
                filename=pdf_path.name,
                doc_type=doc_type,
                text_length=len(result.raw_text),
                pages=result.metadata.get('pages', 0),
                extraction_time_ms=processing_time,
                chunks_count=0,  # Sera mis √† jour en phase 3
                key_elements=key_elements,
                requirements=requirements,
                risks=risks,
                score=doc_score
            )

            documents_analysis.append(doc_analysis)
            self.documents[doc_type] = result.raw_text

            logger.info(f"‚úÖ Document trait√© avec succ√®s")
            logger.info(f"   üìù Texte extrait: {len(result.raw_text):,} caract√®res")
            logger.info(f"   üìä {len(requirements)} exigences d√©tect√©es")
            logger.info(f"   ‚ö†Ô∏è {len(risks)} risques identifi√©s")
            logger.info(f"   üéØ Score: {doc_score:.1f}%")

            # Afficher un aper√ßu des √©l√©ments cl√©s
            if key_elements:
                logger.info(f"\nüìå √âl√©ments cl√©s extraits:")
                for key, value in list(key_elements.items())[:5]:
                    if isinstance(value, str):
                        value_preview = value[:100] + "..." if len(value) > 100 else value
                    else:
                        value_preview = str(value)
                    logger.info(f"   ‚Ä¢ {key}: {value_preview}")

        logger.info(f"\n‚úÖ Phase 1 termin√©e: {len(documents_analysis)} documents analys√©s")
        return documents_analysis

    async def _phase2_cross_document_analysis(self, documents: List[DocumentAnalysis]) -> CrossDocumentAnalysis:
        """Phase 2: Analyse crois√©e des documents"""

        logger.info("\n" + "="*60)
        logger.info("üîç PHASE 2: ANALYSE CROIS√âE DES DOCUMENTS")
        logger.info("="*60)

        # Collecter toutes les exigences
        all_requirements = []
        for doc in documents:
            all_requirements.extend(doc.requirements)

        total_requirements = len(set(all_requirements))
        logger.info(f"üìã Total des exigences uniques: {total_requirements}")

        # D√©tecter les contradictions
        contradictions = self._detect_contradictions(documents)
        logger.info(f"‚ö†Ô∏è Contradictions d√©tect√©es: {len(contradictions)}")

        # Identifier les √©l√©ments manquants
        missing_elements = self._identify_missing_elements(documents)
        logger.info(f"‚ùå √âl√©ments manquants: {len(missing_elements)}")

        # V√©rifier la coh√©rence temporelle
        timeline_consistency = self._check_timeline_consistency(documents)
        logger.info(f"‚è∞ Coh√©rence temporelle: {'‚úÖ OK' if timeline_consistency else '‚ùå Probl√®me'}")

        # √âvaluer la clart√© financi√®re
        financial_clarity = self._assess_financial_clarity(documents)
        logger.info(f"üí∞ Clart√© financi√®re: {financial_clarity:.1f}%")

        # √âvaluer la complexit√© technique
        technical_complexity = self._assess_technical_complexity(documents)
        logger.info(f"üîß Complexit√© technique: {technical_complexity:.1f}/100")

        # Calculer le score global
        global_score = self._calculate_global_score(
            contradictions, missing_elements, timeline_consistency,
            financial_clarity, technical_complexity
        )

        logger.info(f"\nüéØ Score global de l'AO: {global_score:.1f}%")

        # Afficher les probl√®mes principaux
        if contradictions:
            logger.info("\nüìç Principales contradictions:")
            for contr in contradictions[:3]:
                logger.info(f"   ‚Ä¢ {contr['description']}")

        if missing_elements:
            logger.info("\nüìç √âl√©ments critiques manquants:")
            for elem in missing_elements[:5]:
                logger.info(f"   ‚Ä¢ {elem}")

        return CrossDocumentAnalysis(
            total_requirements=total_requirements,
            contradictions=contradictions,
            missing_elements=missing_elements,
            timeline_consistency=timeline_consistency,
            financial_clarity=financial_clarity,
            technical_complexity=technical_complexity,
            global_score=global_score
        )

    async def _phase3_optimized_chunking(self, documents: List[DocumentAnalysis]):
        """Phase 3: Chunking optimis√© par type de document"""

        logger.info("\n" + "="*60)
        logger.info("üìö PHASE 3: CHUNKING OPTIMIS√â ET INDEXATION")
        logger.info("="*60)

        from src.services.ai.chunking_service import ChunkingService
        chunking_service = ChunkingService()

        total_chunks = 0

        for doc_type, text in self.documents.items():
            logger.info(f"\nüìÑ Chunking du document: {doc_type}")

            # Strat√©gie de chunking adapt√©e au type de document
            chunk_size = self._get_optimal_chunk_size(doc_type)
            overlap = self._get_optimal_overlap(doc_type)

            logger.info(f"   Strat√©gie: chunk_size={chunk_size}, overlap={overlap}")

            # Cr√©er un objet ProcessingResult factice pour le chunking
            from src.processors.base import ProcessingResult
            processing_result = ProcessingResult(
                raw_text=text,
                structured_content={},
                success=True,
                processing_time_ms=100,
                processor_name="PDFProcessor",
                processor_version="1.0",
                page_count=0,
                word_count=len(text.split()),
                metadata={'document_type': doc_type}
            )

            # G√©n√©rer les chunks
            chunks = await chunking_service.chunk_document(
                processing_result=processing_result,
                document_id=str(uuid.uuid4())
            )

            self.chunks_db[doc_type] = chunks
            total_chunks += len(chunks)

            logger.info(f"   ‚úÖ {len(chunks)} chunks cr√©√©s")

            # Mettre √† jour le compte de chunks dans l'analyse
            for doc_analysis in documents:
                if doc_analysis.doc_type == doc_type:
                    doc_analysis.chunks_count = len(chunks)

        logger.info(f"\n‚úÖ Phase 3 termin√©e: {total_chunks} chunks cr√©√©s au total")

    async def _phase4_advanced_rag_queries(self) -> Dict[str, List[Dict[str, str]]]:
        """Phase 4: 30+ requ√™tes RAG avanc√©es"""

        logger.info("\n" + "="*60)
        logger.info("ü§ñ PHASE 4: REQU√äTES RAG AVANC√âES (30+ QUESTIONS)")
        logger.info("="*60)

        from src.services.ai.mistral_service import get_mistral_service
        from src.services.ai.prompt_templates import PromptTemplates

        mistral_service = get_mistral_service()

        # Pr√©parer le contexte unifi√©
        context_parts = []
        for doc_type, chunks in self.chunks_db.items():
            context_parts.append(f"\n=== {doc_type} ===\n")
            # Prendre les chunks les plus pertinents
            for chunk in chunks[:10]:
                context_parts.append(chunk.chunk_text[:500])

        unified_context = "\n".join(context_parts)

        # D√©finir les cat√©gories de questions
        rag_queries = {
            "administratif": [
                "Quelle est la date limite de remise des offres ?",
                "Quels sont les documents obligatoires √† fournir dans l'offre ?",
                "Quelle est la dur√©e du march√© et ses conditions de renouvellement ?",
                "Quels sont les crit√®res d'attribution et leur pond√©ration ?",
                "Quelles sont les conditions de recevabilit√© des offres ?",
                "Y a-t-il une visite obligatoire des sites ? Si oui, quand ?",
            ],
            "technique": [
                "Quelles sont les principales sp√©cifications techniques requises ?",
                "Quelles normes et certifications sont exig√©es ?",
                "Quel est le p√©rim√®tre technique exact du march√© ?",
                "Quelles sont les contraintes d'architecture technique ?",
                "Quels sont les niveaux de service (SLA) attendus ?",
                "Quelles sont les exigences de s√©curit√© informatique ?",
            ],
            "contractuel": [
                "Quelles sont les p√©nalit√©s pr√©vues en cas de retard ou d√©faillance ?",
                "Quelle est la r√©partition des responsabilit√©s entre les parties ?",
                "Quelles sont les conditions de r√©siliation du march√© ?",
                "Quelles garanties sont exig√©es (bancaire, performance, etc.) ?",
                "Quelles sont les obligations en mati√®re d'assurance ?",
                "Comment sont g√©r√©es les modifications du contrat ?",
            ],
            "financier": [
                "Quel est le mode de d√©termination des prix (forfait, BPU, etc.) ?",
                "Quelles sont les modalit√©s de paiement et d√©lais ?",
                "Y a-t-il une clause de r√©vision des prix ?",
                "Quel est le budget estim√© ou maximum du march√© ?",
                "Quelles sont les conditions de facturation ?",
                "Y a-t-il des options ou tranches conditionnelles ?",
            ],
            "risques": [
                "Quels sont les principaux risques techniques identifi√©s ?",
                "Y a-t-il des contradictions entre les diff√©rents documents ?",
                "Quelles sont les zones d'ambigu√Øt√© dans les sp√©cifications ?",
                "Les d√©lais sont-ils r√©alistes par rapport √† la complexit√© ?",
                "Y a-t-il des clauses potentiellement abusives ou d√©s√©quilibr√©es ?",
                "Quels sont les risques de d√©pendance ou de lock-in ?",
            ],
            "strat√©gique": [
                "Quel est le contexte et les enjeux du march√© pour l'acheteur ?",
                "Qui sont les concurrents probables sur ce march√© ?",
                "Quels sont les facteurs cl√©s de succ√®s pour remporter ce march√© ?",
                "Quelle strat√©gie de r√©ponse est recommand√©e ?",
                "Faut-il r√©pondre seul ou en groupement ?",
                "Quels sont les points de diff√©renciation √† mettre en avant ?",
            ]
        }

        insights = {}
        total_queries = sum(len(queries) for queries in rag_queries.values())
        current_query = 0

        for category, queries in rag_queries.items():
            logger.info(f"\nüìù Cat√©gorie: {category.upper()}")
            logger.info("-" * 40)

            category_insights = []

            for query in queries:
                current_query += 1
                logger.info(f"\n‚ùì [{current_query}/{total_queries}] {query}")

                # G√©n√©rer le prompt avec contexte
                prompt = PromptTemplates.rag_query_prompt(
                    query=query,
                    context=unified_context[:3000]  # Limiter la taille du contexte
                )

                try:
                    # Pause pour respecter les rate limits
                    await asyncio.sleep(2)

                    # G√©n√©rer la r√©ponse
                    response = await mistral_service.generate_completion(
                        prompt=prompt,
                        max_tokens=300,
                        temperature=0.1
                    )

                    if response:
                        # Nettoyer et formater la r√©ponse
                        clean_response = response.strip()

                        # Afficher un aper√ßu
                        preview = clean_response[:200] + "..." if len(clean_response) > 200 else clean_response
                        logger.info(f"üí° R√©ponse: {preview}")

                        category_insights.append({
                            "question": query,
                            "answer": clean_response,
                            "confidence": self._assess_answer_confidence(clean_response)
                        })
                    else:
                        logger.warning(f"‚ö†Ô∏è Pas de r√©ponse g√©n√©r√©e")
                        category_insights.append({
                            "question": query,
                            "answer": "Information non trouv√©e dans les documents",
                            "confidence": 0.0
                        })

                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erreur lors de la requ√™te: {str(e)[:100]}")
                    category_insights.append({
                        "question": query,
                        "answer": "Erreur lors de l'analyse",
                        "confidence": 0.0
                    })
                    await asyncio.sleep(5)  # Pause plus longue en cas d'erreur

            insights[category] = category_insights

            # R√©sum√© de la cat√©gorie
            avg_confidence = sum(i["confidence"] for i in category_insights) / len(category_insights)
            logger.info(f"\n‚úÖ Cat√©gorie {category}: {len(category_insights)} r√©ponses, confiance moyenne: {avg_confidence:.1f}%")

        logger.info(f"\n‚úÖ Phase 4 termin√©e: {current_query} requ√™tes trait√©es")
        return insights

    async def _phase5_conformity_analysis(self) -> Dict[str, Any]:
        """Phase 5: Analyse de conformit√© d√©taill√©e"""

        logger.info("\n" + "="*60)
        logger.info("‚úîÔ∏è PHASE 5: ANALYSE DE CONFORMIT√â")
        logger.info("="*60)

        conformity_checks = {
            "completude_dossier": {
                "check": "Tous les documents essentiels sont pr√©sents",
                "status": self._check_dossier_completeness(),
                "impact": "critical"
            },
            "coherence_delais": {
                "check": "Les d√©lais sont coh√©rents entre les documents",
                "status": self._check_timeline_coherence(),
                "impact": "high"
            },
            "clarte_financiere": {
                "check": "Les aspects financiers sont clairement d√©finis",
                "status": self._check_financial_clarity(),
                "impact": "high"
            },
            "specifications_techniques": {
                "check": "Les sp√©cifications techniques sont compl√®tes",
                "status": self._check_technical_specs(),
                "impact": "high"
            },
            "criteres_selection": {
                "check": "Les crit√®res de s√©lection sont explicites",
                "status": self._check_selection_criteria(),
                "impact": "critical"
            },
            "risques_contractuels": {
                "check": "Absence de clauses abusives ou d√©s√©quilibr√©es",
                "status": self._check_contractual_risks(),
                "impact": "medium"
            }
        }

        # Calculer le score de conformit√©
        total_score = 0
        weights = {"critical": 3, "high": 2, "medium": 1}
        total_weight = 0

        logger.info("\nüìã R√©sultats de conformit√©:")
        for check_name, check_data in conformity_checks.items():
            status_icon = "‚úÖ" if check_data["status"] else "‚ùå"
            logger.info(f"   {status_icon} {check_data['check']}")

            if check_data["status"]:
                total_score += weights[check_data["impact"]]
            total_weight += weights[check_data["impact"]]

        conformity_score = (total_score / total_weight) * 100 if total_weight > 0 else 0

        logger.info(f"\nüéØ Score de conformit√© global: {conformity_score:.1f}%")

        return {
            "checks": conformity_checks,
            "score": conformity_score,
            "recommendation": self._get_conformity_recommendation(conformity_score)
        }

    async def _phase6_generate_bid_manager_report(
        self,
        documents: List[DocumentAnalysis],
        cross_analysis: CrossDocumentAnalysis,
        rag_insights: Dict[str, List[Dict[str, str]]],
        conformity: Dict[str, Any]
    ) -> BidManagerReport:
        """Phase 6: G√©n√©ration du rapport Bid Manager"""

        logger.info("\n" + "="*60)
        logger.info("üìë PHASE 6: G√âN√âRATION DU RAPPORT BID MANAGER")
        logger.info("="*60)

        # Calculer le score GO/NO-GO
        go_no_go_score = self._calculate_go_no_go_score(
            cross_analysis, conformity, rag_insights
        )

        # D√©terminer la d√©cision
        if go_no_go_score >= 75:
            decision = "GO - Opportunit√© favorable"
        elif go_no_go_score >= 50:
            decision = "GO CONDITIONNEL - N√©cessite des clarifications"
        else:
            decision = "NO-GO - Risques trop √©lev√©s"

        logger.info(f"\nüéØ Score GO/NO-GO: {go_no_go_score:.1f}%")
        logger.info(f"üìä D√©cision: {decision}")

        # Identifier les risques cl√©s
        key_risks = self._compile_key_risks(documents, cross_analysis, conformity)
        logger.info(f"\n‚ö†Ô∏è {len(key_risks)} risques majeurs identifi√©s")

        # G√©n√©rer le plan d'action
        action_plan = self._generate_action_plan(
            cross_analysis, conformity, rag_insights
        )
        logger.info(f"üìã {len(action_plan)} actions prioritaires d√©finies")

        # Pr√©parer les questions pour l'acheteur
        questions_for_buyer = self._generate_questions_for_buyer(
            cross_analysis, rag_insights
        )
        logger.info(f"‚ùì {len(questions_for_buyer)} questions √† poser √† l'acheteur")

        # Analyse concurrentielle
        competitive_positioning = self._analyze_competitive_positioning(
            documents, cross_analysis
        )

        # G√©n√©rer le r√©sum√© ex√©cutif
        executive_summary = self._generate_executive_summary(
            documents, cross_analysis, go_no_go_score, decision
        )

        # Cr√©er le rapport final
        report = BidManagerReport(
            ao_reference="VSGP-2024-INFOGERANCE",
            analysis_date=datetime.now().isoformat(),
            documents_analyzed=documents,
            cross_analysis=cross_analysis,
            rag_insights=rag_insights,
            go_no_go_score=go_no_go_score,
            go_no_go_decision=decision,
            key_risks=key_risks,
            action_plan=action_plan,
            questions_for_buyer=questions_for_buyer,
            competitive_positioning=competitive_positioning,
            executive_summary=executive_summary
        )

        # Sauvegarder le rapport
        await self._save_report(report)

        # Afficher le rapport final
        await self._display_final_report(report)

        return report

    # M√©thodes utilitaires

    def _determine_doc_type(self, filename: str) -> str:
        """D√©termine le type de document bas√© sur le nom du fichier"""
        filename_upper = filename.upper()
        if "CCTP" in filename_upper:
            return "CCTP"
        elif "CCAP" in filename_upper:
            return "CCAP"
        elif "RC" in filename_upper or "REGLEMENT" in filename_upper:
            return "RC"
        else:
            return "OTHER"

    async def _extract_key_elements(self, text: str, doc_type: str) -> Dict[str, Any]:
        """Extrait les √©l√©ments cl√©s selon le type de document"""
        elements = {}

        if doc_type == "CCTP":
            # √âl√©ments techniques
            elements["objet"] = self._extract_pattern(text, r"objet[:\s]+(.{50,200})", "Objet non sp√©cifi√©")
            elements["perimetre"] = self._extract_pattern(text, r"p√©rim√®tre[:\s]+(.{50,300})", "P√©rim√®tre √† d√©terminer")
            elements["normes"] = re.findall(r"\b(?:ISO|EN|NF)[^\s]{2,15}\b", text)
            elements["sla_mentions"] = len(re.findall(r"(?:SLA|niveau.{0,5}service|disponibilit√©)", text, re.I))

        elif doc_type == "CCAP":
            # √âl√©ments administratifs
            elements["duree"] = self._extract_pattern(text, r"dur√©e.{0,20}(?:march√©|contrat)[:\s]+(.{10,100})", "Non sp√©cifi√©e")
            elements["penalites"] = len(re.findall(r"p√©nalit√©", text, re.I))
            elements["garanties"] = re.findall(r"garantie.{0,30}", text, re.I)[:3]
            elements["prix_type"] = self._detect_price_type(text)

        elif doc_type == "RC":
            # √âl√©ments de consultation
            elements["date_limite"] = self._extract_pattern(text, r"date.{0,10}limite.{0,30}(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})", "√Ä v√©rifier")
            elements["criteres"] = self._extract_selection_criteria(text)
            elements["documents_requis"] = self._extract_required_docs(text)

        return elements

    def _extract_pattern(self, text: str, pattern: str, default: str) -> str:
        """Extrait un motif du texte avec valeur par d√©faut"""
        match = re.search(pattern, text, re.I | re.S)
        if match:
            return match.group(1).strip()[:200]
        return default

    def _detect_price_type(self, text: str) -> str:
        """D√©tecte le type de prix dans le march√©"""
        if re.search(r"prix.{0,10}forfaitaire", text, re.I):
            return "Forfaitaire"
        elif re.search(r"bordereau.{0,10}prix|BPU", text, re.I):
            return "Bordereau de prix unitaires"
        elif re.search(r"r√©gie", text, re.I):
            return "R√©gie"
        else:
            return "Non d√©termin√©"

    def _extract_selection_criteria(self, text: str) -> List[str]:
        """Extrait les crit√®res de s√©lection"""
        criteria = []
        patterns = [
            r"prix.{0,20}(\d{1,3})\s*%",
            r"valeur.{0,10}technique.{0,20}(\d{1,3})\s*%",
            r"d√©lai.{0,20}(\d{1,3})\s*%",
            r"qualit√©.{0,20}(\d{1,3})\s*%"
        ]
        for pattern in patterns:
            matches = re.findall(pattern, text, re.I)
            if matches:
                criteria.extend(matches)
        return criteria

    def _extract_required_docs(self, text: str) -> List[str]:
        """Extrait la liste des documents requis"""
        docs = []
        doc_patterns = [
            "m√©moire technique",
            "DC1", "DC2", "DC4",
            "attestation", "certificat",
            "r√©f√©rences", "CV"
        ]
        for pattern in doc_patterns:
            if re.search(pattern, text, re.I):
                docs.append(pattern)
        return docs

    def _extract_requirements(self, text: str, doc_type: str) -> List[str]:
        """Extrait les exigences selon le type de document"""
        requirements = []

        # Patterns g√©n√©riques d'exigences
        requirement_patterns = [
            r"(?:doit|devra|devront|obligatoire).{0,100}",
            r"(?:exig√©|requis|n√©cessaire).{0,100}",
            r"(?:au minimum|au moins|minimal).{0,100}"
        ]

        for pattern in requirement_patterns:
            matches = re.findall(pattern, text, re.I)
            requirements.extend([m[:150] for m in matches[:10]])  # Limiter √† 10 par pattern

        return list(set(requirements))[:30]  # Garder max 30 exigences uniques

    def _identify_risks(self, text: str, doc_type: str) -> List[Dict[str, str]]:
        """Identifie les risques dans le document"""
        risks = []

        # Recherche de termes de risque
        risk_indicators = {
            "p√©nalit√©": "contractuel",
            "r√©siliation": "contractuel",
            "exclusif": "commercial",
            "propri√©t√© intellectuelle": "juridique",
            "RGPD": "conformit√©",
            "d√©lai.{0,10}court": "planning",
            "complexe": "technique",
            "migration": "technique"
        }

        for indicator, risk_type in risk_indicators.items():
            if re.search(indicator, text, re.I):
                risks.append({
                    "type": risk_type,
                    "indicator": indicator.replace(".{0,10}", ""),
                    "severity": "medium"
                })

        return risks[:10]  # Limiter aux 10 risques principaux

    def _calculate_document_score(self, elements: Dict, requirements: List, risks: List) -> float:
        """Calcule le score de qualit√© d'un document"""
        score = 50.0  # Score de base

        # Bonus pour les √©l√©ments trouv√©s
        score += min(len(elements) * 5, 25)

        # Bonus pour les exigences claires
        score += min(len(requirements) * 2, 20)

        # P√©nalit√© pour les risques
        score -= min(len(risks) * 3, 15)

        # S'assurer que le score reste entre 0 et 100
        return max(0, min(100, score))

    def _detect_contradictions(self, documents: List[DocumentAnalysis]) -> List[Dict[str, str]]:
        """D√©tecte les contradictions entre documents"""
        contradictions = []

        # V√©rifier les d√©lais contradictoires
        delays = []
        for doc in documents:
            text = self.documents.get(doc.doc_type, "")
            delay_matches = re.findall(r"(\d+)\s*(?:jour|mois|semaine)", text, re.I)
            delays.extend([(doc.doc_type, m) for m in delay_matches])

        if delays and len(set(d[1] for d in delays)) > 5:
            contradictions.append({
                "type": "d√©lais",
                "description": "Incoh√©rence dans les d√©lais mentionn√©s entre documents",
                "severity": "high"
            })

        return contradictions

    def _identify_missing_elements(self, documents: List[DocumentAnalysis]) -> List[str]:
        """Identifie les √©l√©ments manquants critiques"""
        missing = []
        doc_types = [doc.doc_type for doc in documents]

        # √âl√©ments essentiels attendus
        if "CCTP" in doc_types:
            cctp_text = self.documents.get("CCTP", "")
            if not re.search(r"p√©rim√®tre", cctp_text, re.I):
                missing.append("P√©rim√®tre technique non clairement d√©fini dans CCTP")

        if "CCAP" in doc_types:
            ccap_text = self.documents.get("CCAP", "")
            if not re.search(r"modalit√©.{0,10}paiement", ccap_text, re.I):
                missing.append("Modalit√©s de paiement non sp√©cifi√©es dans CCAP")

        if "RC" in doc_types:
            rc_text = self.documents.get("RC", "")
            if not re.search(r"crit√®re.{0,20}(?:s√©lection|attribution)", rc_text, re.I):
                missing.append("Crit√®res de s√©lection non explicites dans RC")

        return missing

    def _check_timeline_consistency(self, documents: List[DocumentAnalysis]) -> bool:
        """V√©rifie la coh√©rence temporelle entre documents"""
        all_dates = []
        for doc in documents:
            text = self.documents.get(doc.doc_type, "")
            date_matches = re.findall(r"\d{1,2}[/-]\d{1,2}[/-]\d{2,4}", text)
            all_dates.extend(date_matches)

        # Si on a des dates, v√©rifier qu'elles sont coh√©rentes
        return len(all_dates) > 0 and len(set(all_dates)) < 10

    def _assess_financial_clarity(self, documents: List[DocumentAnalysis]) -> float:
        """√âvalue la clart√© des aspects financiers"""
        score = 0.0
        indicators = 0

        for doc in documents:
            text = self.documents.get(doc.doc_type, "")
            if re.search(r"prix", text, re.I):
                score += 20
                indicators += 1
            if re.search(r"budget", text, re.I):
                score += 30
                indicators += 1
            if re.search(r"modalit√©.{0,10}paiement", text, re.I):
                score += 25
                indicators += 1
            if re.search(r"r√©vision.{0,10}prix", text, re.I):
                score += 25
                indicators += 1

        return min(100, score)

    def _assess_technical_complexity(self, documents: List[DocumentAnalysis]) -> float:
        """√âvalue la complexit√© technique du march√©"""
        complexity = 30.0  # Complexit√© de base

        cctp_text = self.documents.get("CCTP", "")

        # Indicateurs de complexit√©
        if re.search(r"migration", cctp_text, re.I):
            complexity += 20
        if re.search(r"haute.{0,10}disponibilit√©|24.{0,5}7", cctp_text, re.I):
            complexity += 15
        if re.search(r"s√©curit√©", cctp_text, re.I):
            complexity += 10
        if len(re.findall(r"interface", cctp_text, re.I)) > 3:
            complexity += 15
        if re.search(r"RGPD|conformit√©", cctp_text, re.I):
            complexity += 10

        return min(100, complexity)

    def _calculate_global_score(
        self, contradictions, missing, timeline_ok, financial_clarity, tech_complexity
    ) -> float:
        """Calcule le score global de l'appel d'offres"""
        score = 70.0  # Score de base

        # P√©nalit√©s
        score -= len(contradictions) * 5
        score -= len(missing) * 3
        if not timeline_ok:
            score -= 10

        # Bonus
        score += financial_clarity * 0.2

        # Ajustement complexit√© (peut √™tre positif ou n√©gatif)
        if tech_complexity > 70:
            score -= 10  # Tr√®s complexe = plus risqu√©
        elif tech_complexity < 40:
            score += 5   # Simple = plus accessible

        return max(0, min(100, score))

    def _get_optimal_chunk_size(self, doc_type: str) -> int:
        """Retourne la taille de chunk optimale selon le type de document"""
        sizes = {
            "CCTP": 1536,  # Plus gros chunks pour le technique
            "CCAP": 1024,  # Chunks moyens pour l'administratif
            "RC": 768,     # Petits chunks pour les r√®gles
            "OTHER": 1024
        }
        return sizes.get(doc_type, 1024)

    def _get_optimal_overlap(self, doc_type: str) -> int:
        """Retourne l'overlap optimal selon le type de document"""
        overlaps = {
            "CCTP": 150,
            "CCAP": 100,
            "RC": 50,
            "OTHER": 100
        }
        return overlaps.get(doc_type, 100)

    def _assess_answer_confidence(self, answer: str) -> float:
        """√âvalue la confiance d'une r√©ponse RAG"""
        confidence = 50.0

        # Indicateurs de haute confiance
        if re.search(r"(?:clairement|explicitement|sp√©cifiquement)", answer, re.I):
            confidence += 20
        if re.search(r"article \d+|section \d+|page \d+", answer, re.I):
            confidence += 15
        if len(answer) > 100:
            confidence += 10

        # Indicateurs de basse confiance
        if re.search(r"(?:pas.{0,10}trouv√©|non.{0,10}mentionn√©|aucune.{0,10}information)", answer, re.I):
            confidence -= 30
        if re.search(r"(?:probablement|peut-√™tre|semble)", answer, re.I):
            confidence -= 15

        return max(0, min(100, confidence))

    def _check_dossier_completeness(self) -> bool:
        """V√©rifie la compl√©tude du dossier"""
        return all(doc_type in self.documents for doc_type in ["CCTP", "CCAP", "RC"])

    def _check_timeline_coherence(self) -> bool:
        """V√©rifie la coh√©rence des d√©lais"""
        # Simplifi√© pour l'exemple
        return True

    def _check_financial_clarity(self) -> bool:
        """V√©rifie la clart√© financi√®re"""
        ccap_text = self.documents.get("CCAP", "")
        return bool(re.search(r"prix|modalit√©.{0,10}paiement", ccap_text, re.I))

    def _check_technical_specs(self) -> bool:
        """V√©rifie la compl√©tude des specs techniques"""
        cctp_text = self.documents.get("CCTP", "")
        return len(cctp_text) > 10000  # Au moins 10k caract√®res

    def _check_selection_criteria(self) -> bool:
        """V√©rifie la pr√©sence de crit√®res de s√©lection"""
        rc_text = self.documents.get("RC", "")
        return bool(re.search(r"crit√®re", rc_text, re.I))

    def _check_contractual_risks(self) -> bool:
        """V√©rifie l'absence de clauses abusives"""
        ccap_text = self.documents.get("CCAP", "")
        # Recherche de termes probl√©matiques
        risky_terms = ["exclusivit√© totale", "p√©nalit√©.{0,20}illimit√©e", "r√©siliation.{0,20}sans.{0,10}pr√©avis"]
        for term in risky_terms:
            if re.search(term, ccap_text, re.I):
                return False
        return True

    def _get_conformity_recommendation(self, score: float) -> str:
        """G√©n√®re une recommandation bas√©e sur le score de conformit√©"""
        if score >= 80:
            return "Dossier conforme - Peut r√©pondre en l'√©tat"
        elif score >= 60:
            return "Dossier globalement conforme - Quelques clarifications n√©cessaires"
        elif score >= 40:
            return "Conformit√© partielle - Demander des pr√©cisions importantes"
        else:
            return "Non-conformit√© majeure - Risque √©lev√©"

    def _calculate_go_no_go_score(
        self, cross_analysis, conformity, rag_insights
    ) -> float:
        """Calcule le score GO/NO-GO final"""
        score = 0.0

        # Poids des diff√©rents facteurs
        score += cross_analysis.global_score * 0.3
        score += conformity["score"] * 0.3

        # Score bas√© sur les insights RAG
        total_confidence = 0
        total_questions = 0
        for category_insights in rag_insights.values():
            for insight in category_insights:
                total_confidence += insight.get("confidence", 0)
                total_questions += 1

        if total_questions > 0:
            avg_confidence = total_confidence / total_questions
            score += avg_confidence * 0.4

        return min(100, score)

    def _compile_key_risks(
        self, documents, cross_analysis, conformity
    ) -> List[Dict[str, str]]:
        """Compile les risques majeurs identifi√©s"""
        risks = []

        # Risques des documents
        for doc in documents:
            for risk in doc.risks[:2]:  # Top 2 par document
                risks.append({
                    "source": doc.doc_type,
                    "type": risk["type"],
                    "description": f"Risque {risk['type']} identifi√© dans {doc.doc_type}",
                    "severity": risk["severity"],
                    "mitigation": self._suggest_mitigation(risk["type"])
                })

        # Risques de l'analyse crois√©e
        if cross_analysis.contradictions:
            risks.append({
                "source": "Analyse crois√©e",
                "type": "coh√©rence",
                "description": f"{len(cross_analysis.contradictions)} contradictions entre documents",
                "severity": "high",
                "mitigation": "Demander clarification lors des questions"
            })

        return risks[:10]  # Top 10 risques

    def _suggest_mitigation(self, risk_type: str) -> str:
        """Sugg√®re une mitigation pour un type de risque"""
        mitigations = {
            "contractuel": "N√©gocier les clauses ou pr√©voir des r√©serves",
            "technique": "Mobiliser expertise technique ou sous-traiter",
            "planning": "Pr√©voir des ressources suppl√©mentaires",
            "commercial": "Analyser la concurrence et adapter l'offre",
            "juridique": "Consultation juridique avant soumission",
            "conformit√©": "Audit de conformit√© et plan d'action"
        }
        return mitigations.get(risk_type, "Analyser en d√©tail et pr√©voir contingence")

    def _generate_action_plan(
        self, cross_analysis, conformity, rag_insights
    ) -> List[Dict[str, str]]:
        """G√©n√®re le plan d'action prioritaire"""
        actions = []

        # Actions bas√©es sur la conformit√©
        if conformity["score"] < 80:
            actions.append({
                "priority": "HIGH",
                "action": "Analyser les points de non-conformit√©",
                "deadline": "J+2",
                "responsible": "√âquipe technique"
            })

        # Actions bas√©es sur les √©l√©ments manquants
        if cross_analysis.missing_elements:
            actions.append({
                "priority": "HIGH",
                "action": "Demander les √©l√©ments manquants √† l'acheteur",
                "deadline": "J+1",
                "responsible": "Bid Manager"
            })

        # Actions standard
        actions.extend([
            {
                "priority": "HIGH",
                "action": "R√©diger les questions pour l'acheteur",
                "deadline": "J+1",
                "responsible": "Bid Manager"
            },
            {
                "priority": "MEDIUM",
                "action": "Estimer les co√ªts et ressources",
                "deadline": "J+3",
                "responsible": "√âquipe commerciale"
            },
            {
                "priority": "MEDIUM",
                "action": "Identifier les partenaires potentiels",
                "deadline": "J+5",
                "responsible": "Direction commerciale"
            },
            {
                "priority": "LOW",
                "action": "Pr√©parer la structure du m√©moire technique",
                "deadline": "J+7",
                "responsible": "√âquipe technique"
            }
        ])

        return actions

    def _generate_questions_for_buyer(
        self, cross_analysis, rag_insights
    ) -> List[str]:
        """G√©n√®re les questions √† poser √† l'acheteur"""
        questions = []

        # Questions sur les √©l√©ments manquants
        for missing in cross_analysis.missing_elements[:3]:
            questions.append(f"Pouvez-vous clarifier : {missing} ?")

        # Questions sur les contradictions
        for contradiction in cross_analysis.contradictions[:2]:
            questions.append(f"Clarification n√©cessaire sur : {contradiction['description']}")

        # Questions standards importantes
        questions.extend([
            "Y a-t-il un budget pr√©visionnel pour ce march√© ?",
            "Une visite des sites est-elle possible/obligatoire ?",
            "Acceptez-vous les variantes techniques ?",
            "Quelle est la date pr√©visionnelle de d√©marrage des prestations ?",
            "Y a-t-il des titulaires sortants ? Si oui, lesquels ?"
        ])

        return questions[:10]

    def _analyze_competitive_positioning(
        self, documents, cross_analysis
    ) -> Dict[str, Any]:
        """Analyse le positionnement concurrentiel"""
        return {
            "market_complexity": "√âlev√©e" if cross_analysis.technical_complexity > 70 else "Moyenne",
            "expected_competitors": "5-8 ESN nationales et r√©gionales",
            "our_strengths": [
                "Expertise sectorielle",
                "Proximit√© g√©ographique",
                "R√©f√©rences similaires"
            ],
            "our_weaknesses": [
                "Taille de structure",
                "Couverture nationale limit√©e"
            ],
            "differentiation_strategy": "Miser sur la proximit√© et la r√©activit√©",
            "pricing_strategy": "Alignement march√© avec value-added services"
        }

    def _generate_executive_summary(
        self, documents, cross_analysis, go_no_go_score, decision
    ) -> str:
        """G√©n√®re le r√©sum√© ex√©cutif"""
        return f"""
R√âSUM√â EX√âCUTIF - ANALYSE AO VSGP INFOG√âRANCE

‚Ä¢ Appel d'offres : March√© public d'infog√©rance pour Vall√©e Sud - Grand Paris
‚Ä¢ Documents analys√©s : {len(documents)} ({', '.join([d.doc_type for d in documents])})
‚Ä¢ Score global : {cross_analysis.global_score:.1f}%
‚Ä¢ D√©cision GO/NO-GO : {decision} (Score: {go_no_go_score:.1f}%)

POINTS CL√âS:
- Complexit√© technique : {cross_analysis.technical_complexity:.0f}/100
- Clart√© financi√®re : {cross_analysis.financial_clarity:.0f}%
- {cross_analysis.total_requirements} exigences identifi√©es
- {len(cross_analysis.contradictions)} points de vigilance

RECOMMANDATION:
{self._get_conformity_recommendation(go_no_go_score)}

PROCHAINES √âTAPES:
1. Envoyer les questions √† l'acheteur (J+1)
2. √âvaluer les ressources n√©cessaires (J+3)
3. D√©cision finale de soumission (J+5)
"""

    async def _save_report(self, report: BidManagerReport):
        """Sauvegarde le rapport en JSON"""
        filename = f"ao_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        # Convertir le rapport en dictionnaire COMPLET
        report_dict = {
            "ao_reference": report.ao_reference,
            "analysis_date": report.analysis_date,
            "go_no_go_score": report.go_no_go_score,
            "go_no_go_decision": report.go_no_go_decision,
            "executive_summary": report.executive_summary,
            "documents_analyzed": [
                {
                    "filename": doc.filename,
                    "type": doc.doc_type,
                    "text_length": doc.text_length,
                    "pages": doc.pages,
                    "score": doc.score,
                    "requirements_count": len(doc.requirements),
                    "risks_count": len(doc.risks)
                } for doc in report.documents_analyzed
            ],
            "cross_analysis": {
                "total_requirements": report.cross_analysis.total_requirements,
                "contradictions_count": len(report.cross_analysis.contradictions),
                "missing_elements_count": len(report.cross_analysis.missing_elements),
                "timeline_consistency": report.cross_analysis.timeline_consistency,
                "financial_clarity": report.cross_analysis.financial_clarity,
                "technical_complexity": report.cross_analysis.technical_complexity,
                "global_score": report.cross_analysis.global_score
            },
            "all_requirements": self._get_all_requirements(report.documents_analyzed),
            "key_risks": [
                {
                    "source": risk["source"],
                    "type": risk["type"],
                    "description": risk["description"],
                    "severity": risk["severity"],
                    "mitigation": risk["mitigation"]
                } for risk in report.key_risks
            ],
            "questions_for_buyer": report.questions_for_buyer,
            "action_plan": report.action_plan,
            "competitive_positioning": report.competitive_positioning,
            "rag_insights_summary": {
                category: {
                    "questions_count": len(insights),
                    "avg_confidence": sum(q["confidence"] for q in insights) / len(insights) if insights else 0
                } for category, insights in report.rag_insights.items()
            }
        }

        # Sauvegarder le rapport complet
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_dict, f, ensure_ascii=False, indent=2)

        # Sauvegarder aussi un fichier s√©par√© avec TOUTES les exigences
        req_filename = f"ao_requirements_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        requirements_dict = {
            "ao_reference": report.ao_reference,
            "analysis_date": report.analysis_date,
            "total_requirements": report.cross_analysis.total_requirements,
            "requirements_by_document": {
                doc.doc_type: doc.requirements for doc in report.documents_analyzed
            },
            "all_unique_requirements": list(set(
                req for doc in report.documents_analyzed for req in doc.requirements
            ))
        }

        with open(req_filename, 'w', encoding='utf-8') as f:
            json.dump(requirements_dict, f, ensure_ascii=False, indent=2)

        logger.info(f"\nüíæ Rapport complet sauvegard√© : {filename}")
        logger.info(f"üìã Liste des exigences sauvegard√©e : {req_filename}")

    def _get_all_requirements(self, documents):
        """Compile toutes les exigences uniques"""
        all_reqs = []
        for doc in documents:
            for req in doc.requirements:
                all_reqs.append({
                    "source": doc.doc_type,
                    "requirement": req
                })
        return all_reqs

    async def _display_final_report(self, report: BidManagerReport):
        """Affiche le rapport final format√©"""

        print("\n" + "="*70)
        print("üìä RAPPORT D'ANALYSE COMPLET - BID MANAGER")
        print("="*70)

        print(report.executive_summary)

        print("\n" + "="*70)
        print("üìà M√âTRIQUES CL√âS")
        print("="*70)
        print(f"‚Ä¢ Documents analys√©s: {len(report.documents_analyzed)}")
        print(f"‚Ä¢ Exigences totales: {report.cross_analysis.total_requirements}")
        print(f"‚Ä¢ Score GO/NO-GO: {report.go_no_go_score:.1f}%")
        print(f"‚Ä¢ D√©cision: {report.go_no_go_decision}")

        print("\n" + "="*70)
        print("‚ö†Ô∏è RISQUES MAJEURS")
        print("="*70)
        for i, risk in enumerate(report.key_risks[:5], 1):
            print(f"{i}. [{risk['severity'].upper()}] {risk['description']}")
            print(f"   ‚Üí Mitigation: {risk['mitigation']}")

        print("\n" + "="*70)
        print("üìã PLAN D'ACTION IMM√âDIAT")
        print("="*70)
        for i, action in enumerate(report.action_plan[:5], 1):
            print(f"{i}. [{action['priority']}] {action['action']}")
            print(f"   √âch√©ance: {action['deadline']} | Responsable: {action['responsible']}")

        print("\n" + "="*70)
        print("‚ùì QUESTIONS POUR L'ACHETEUR")
        print("="*70)
        for i, question in enumerate(report.questions_for_buyer[:5], 1):
            print(f"{i}. {question}")

        print("\n" + "="*70)
        print(f"‚úÖ ANALYSE TERMIN√âE - {datetime.now().strftime('%H:%M:%S')}")
        print("="*70)


async def main():
    """Fonction principale"""
    analyzer = AOCompleteAnalyzer()

    # R√©pertoire contenant les documents de l'AO
    ao_directory = Path("/Users/cedric/Dev/projects/scorpiusProject/Examples/VSGP-AO")

    logger.info("üöÄ D√©marrage de l'analyse compl√®te de l'appel d'offres...")
    logger.info("üìÑ Cette analyse est con√ßue pour un Bid Manager avec 3 ans d'exp√©rience")
    logger.info("-"*70)

    try:
        report = await analyzer.analyze_complete_ao(ao_directory)
        logger.info("\nüéâ Analyse compl√®te termin√©e avec succ√®s!")

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'analyse: {e}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(main())